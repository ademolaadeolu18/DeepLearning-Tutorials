{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input (temperature, rainfall, humidity)\n",
    "inputs = np.array([[78.,67,43],\n",
    "                    [91,88,64],\n",
    "                    [87,134,58],\n",
    "                    [102,43,37],\n",
    "                    [69,96,70]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56., 70],\n",
    "                   [81,101],\n",
    "                   [119,133],\n",
    "                   [22,37],\n",
    "                   [103,119]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 78.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# Converts to torch tensors\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  apple_yield = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
    "#  oranges_yield = w21 * temp + w22 * rainfall + w23 * humidity + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = x * W_transpose + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1936, -0.2251,  0.1586],\n",
      "        [ 0.5389,  1.6675, -0.7479]], requires_grad=True)\n",
      "tensor([-0.7959,  0.3515], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# random initializing the weights and biases\n",
    "w = torch.randn(2,3, requires_grad=True)\n",
    "b = torch.randn(2, requires_grad=True)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "\n",
    "def model(x):\n",
    "    return x @ w.t() + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 84.0466, 121.9484],\n",
      "        [ 98.1678, 148.2650],\n",
      "        [ 82.0859, 227.2998],\n",
      "        [117.1451,  99.3517],\n",
      "        [ 71.0585, 145.2603]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Generate Predictions\n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing the predictions and targets we can see the disparity so we need to improve the value of our weights\n",
    "# to improve our weigths we need to calculate this disparity and begin to reduce it. We will use the mean square error as our loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE Loss\n",
    "def mse(t1,t2):\n",
    "    diff = t1-t2\n",
    "    return torch.sum(diff * diff)/ diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3091.9250, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Compute loss\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1936, -0.2251,  0.1586],\n",
      "        [ 0.5389,  1.6675, -0.7479]], requires_grad=True)\n",
      "tensor([[1607.8429, -106.3495,  289.6379],\n",
      "        [4945.7998, 5095.6274, 2974.6714]])\n"
     ]
    }
   ],
   "source": [
    "# Gradients for weights\n",
    "print(w)\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7959,  0.3515], requires_grad=True)\n",
      "tensor([14.3008, 56.4250])\n"
     ]
    }
   ],
   "source": [
    "print(b)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust weights and reset gradients\n",
    "with torch.no_grad():\n",
    "    w -= w.grad * 1e-5\n",
    "    b -= b.grad * 1e-5\n",
    "    # since pytorch stores the gradiens in the .grad variable we need to reset it to zero\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2526.8291, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train for 100 epochs\n",
    "for i in range(50):\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds, targets)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= w.grad * 1e-5\n",
    "        b -= b.grad * 1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(87.7035, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 57.0156,  71.4299],\n",
       "        [ 81.1875,  91.7465],\n",
       "        [120.1997, 151.3564],\n",
       "        [ 27.3169,  42.5996],\n",
       "        [ 96.2799, 100.4228]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression using pyTorch built-ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs (temp, rainfall, humidity)\n",
    "\n",
    "inputs = np.array([[73,67,43.], [91,88,64],[87,134,58],\n",
    "                  [102,43,37], [69,96,70], [73,67,43],\n",
    "                  [91,88,64], [87,134,58], [102,43,37],\n",
    "                  [69,96,70], [73,67,43], [91,88,64],\n",
    "                  [87,134,58], [102,43,37], [69,96,70]], dtype='float32')\n",
    "\n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56,70.], [81,101], [119,133],\n",
    "                   [22,37], [103,119], [56,70],\n",
    "                   [81,101], [119,133], [22,37],\n",
    "                   [103,119], [56,70], [81,101],\n",
    "                   [119,133], [22,37], [103,119]], dtype='float32')\n",
    "\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to access a small section of data we need to use the  TensorDataset\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 73.,  67.,  43.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 134.,  58.]]),\n",
       " tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can then define the dataset we want to use\n",
    "train_ds = TensorDataset(inputs, targets)\n",
    "train_ds[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " # we can also create a data loader which can split the data into batches of a predefined size while training \n",
    "# it can also be used for shuffling and random sampling of the data\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loader\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 87., 134.,  58.],\n",
      "        [ 69.,  96.,  70.],\n",
      "        [ 69.,  96.,  70.],\n",
      "        [ 69.,  96.,  70.],\n",
      "        [102.,  43.,  37.]])\n",
      "tensor([[119., 133.],\n",
      "        [103., 119.],\n",
      "        [103., 119.],\n",
      "        [103., 119.],\n",
      "        [ 22.,  37.]])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_dl:\n",
    "    print(xb)\n",
    "    print(yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using nn.Linear helps to atomatically create weights and biases for our training\n",
    "# the arguments to the function should be the number of input features and the number of outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3146,  0.5414,  0.2344],\n",
      "        [-0.3231,  0.3189,  0.2156]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0011,  0.5739], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = nn.Linear(3,2)\n",
    "print(model.weight)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.3146,  0.5414,  0.2344],\n",
       "         [-0.3231,  0.3189,  0.2156]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0011,  0.5739], requires_grad=True)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pytorch has a helpful .parameters method that returns a list of all the weights and bias matrices present in the moddel\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 23.3913,   7.6239],\n",
       "        [ 34.0221,  13.0324],\n",
       "        [ 58.7794,  27.7017],\n",
       "        [ -0.1322, -10.6945],\n",
       "        [ 46.6807,  23.9862],\n",
       "        [ 23.3913,   7.6239],\n",
       "        [ 34.0221,  13.0324],\n",
       "        [ 58.7794,  27.7017],\n",
       "        [ -0.1322, -10.6945],\n",
       "        [ 46.6807,  23.9862],\n",
       "        [ 23.3913,   7.6239],\n",
       "        [ 34.0221,  13.0324],\n",
       "        [ 58.7794,  27.7017],\n",
       "        [ -0.1322, -10.6945],\n",
       "        [ 46.6807,  23.9862]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of defining a loss function we will use the built-in mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch to enable call to the loss function\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "loss_fn = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4457.7661, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_fn(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
